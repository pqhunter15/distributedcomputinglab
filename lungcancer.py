# -*- coding: utf-8 -*-
"""lungcancer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1P88pA93R4LoJ37osxLgPgzg1bePL8QRP
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score,
    f1_score, roc_auc_score, confusion_matrix, classification_report
)
import numpy as np

df = pd.read_csv('lung_cancer_dataset (1).csv')

numeric_features = ["age", "pack_years"]
categorical_features = ['gender', 'radon_exposure', 'asbestos_exposure', 'secondhand_smoke_exposure', 'copd_diagnosis', 'alcohol_consumption', 'family_history']
X = df[numeric_features + categorical_features]
y = df["lung_cancer"].apply(lambda x: 1 if x == 'Yes' else 0)

#pre-processing

numeric_pre = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="median")),
    ("scaler", StandardScaler())
])


categorical_pre = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="most_frequent")),
    ("ohe", OneHotEncoder(drop="first", handle_unknown="ignore"))
])

preprocessor = ColumnTransformer(
    transformers=[
        ("num", numeric_pre, numeric_features),
        ("cat", categorical_pre, categorical_features),
    ]
)

#model pipeline

log_reg = LogisticRegression(
    penalty="l2",
    solver="lbfgs",
    max_iter=1000,
    class_weight='balanced'  # or "balanced"
)

pipe = Pipeline(steps=[
    ("preprocess", preprocessor),
    ("model", log_reg),
])

# ==========================================
# 5) Train / test split
# ==========================================
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# ==========================================
# 6) Fit & evaluate
# ==========================================
pipe.fit(X_train, y_train)

y_proba = pipe.predict_proba(X_test)[:, 1]
y_pred_default = (y_proba >= 0.5).astype(int)  #threshold

print("Accuracy :", accuracy_score(y_test, y_pred_default))
print("Precision:", precision_score(y_test, y_pred_default, zero_division=0))
print("Recall   :", recall_score(y_test, y_pred_default))
print("F1       :", f1_score(y_test, y_pred_default))
print("ROC AUC  :", roc_auc_score(y_test, y_proba))
print("\nConfusion matrix:\n", confusion_matrix(y_test, y_pred_default))
print("\nClassification report:\n", classification_report(y_test, y_pred_default))

# ==========================================
# 7) Coefficients & odds ratios
# ==========================================
# Get feature names after preprocessing
ohe = pipe.named_steps["preprocess"].named_transformers_["cat"].named_steps["ohe"]
cat_feature_names = ohe.get_feature_names_out(categorical_features)
all_feature_names = np.r_[numeric_features, cat_feature_names]

coef = pipe.named_steps["model"].coef_.ravel()
intercept = pipe.named_steps["model"].intercept_[0]

coef_df = pd.DataFrame({
    "feature": all_feature_names,
    "coefficient": coef,
    "odds_ratio": np.exp(coef)  # OR = e^(beta)
}).sort_values("odds_ratio", ascending=False)

print("\nIntercept (log-odds):", intercept)
print("\nTop coefficients by odds ratio:\n", coef_df.head(15))


#Tune decision threshold for recall/precision tradeoff
# ==========================================

desired_recall = 0.90
thresholds = np.linspace(0.01, 0.99, 99)

best_thresh, best_diff = 0.5, 1.0
for t in thresholds:
    y_pred_t = (y_proba >= t).astype(int)
    r = recall_score(y_test, y_pred_t)
    if abs(r - desired_recall) < best_diff:
        best_diff = abs(r - desired_recall)
        best_thresh = t

y_pred_tuned = (y_proba >= best_thresh).astype(int)
print(f"\nTuned threshold: {best_thresh:.2f}")
print("Precision:", precision_score(y_test, y_pred_tuned, zero_division=0))
print("Recall   :", recall_score(y_test, y_pred_tuned))
print("F1       :", f1_score(y_test, y_pred_tuned))
